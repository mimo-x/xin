第 8 章
堆
进程的堆内存通常指的是地址空间中区别于代码区和全局数据区的另一个内存区，允许程序在运行
阶段动态地申请所需的内存空间。很多编程语言的runtime实现了自己的堆，例如C语言中为大家所
熟知的malloc（）函数和free（）函数，一方面包揽了向操作系统申请内存页面及内存空间的管理
等工作，另一方面为开发者提供了简单易用的API，使开发者不需要关心底层的细节，只是按需调
用API分配和释放内存就可以了。Go语言的堆内存管理和C语言有一点明显的不同，就是当一段内
存不再使用的时候，不需要开发者手动进行释放，而是由垃圾回收器GC来自动完成。本章从内存
分配和垃圾回收两方面来看一下Go语言的堆内存管理。

8.1 内存分配
在使用其他编程语言的时候，堆内存分配通常是显式的，例如C语言中的malloc（）函数，以及
C++中的new关键字等，基本上在它们出现的地方就意味着堆分配。在Go语言中，我们通常可能会
认为出现new（）函数和make（）函数这两个内置函数的地方就是堆分配，实则不然。编译器会基
于逃逸分析对内存的分配进行优化，有些没有逃逸的变量，即使源代码层面是通过new（）函数或
make（）函数分配的，也不会在堆上分配，那些被认为逃逸的变量，即使没有用到new（）函数和
make（）函数，也会在堆上分配。

在Go的runtime中，有一系列函数被用来分配内存。例如与new语义相对应的有newobject（）函数
和newarray（）函数，分别负责单个对象的分配和数组的分配。与make语义相对应的有
makeslice（）函数、makemap（）函数及makechan（）函数及一些变种，分别负责分配和初始化切
片、map和channel。无论是new系列还是make系列，这些函数的内部无一例外都会调用
runtime.mallocgc（）函数，它就是Go语言堆分配的关键函数。在开始分析mallocgc（）函数之前，
我们需要先了解一些铺垫知识，例如一些关键的常量、数据结构和底层函数之类的。下面我们就先
来了解这些基础内容，本节的最后再回过头来分析mallocgc（）函数。

8.1.1 sizeclasses

Go的堆分配采用了与tcmalloc内存分配器类似的算法，tcmalloc是谷歌公司开发的一款针对C/C++的
内存分配器，在对抗内存碎片化和多核性能方面非常优秀，因此有着很广泛的应用。其他一些编程
语言中也有类似tcmalloc的实现，例如PHP 7参考了tcmalloc的思想对堆分配进行了优化，得到了显
著的性能提升。

参考tcmalloc实现的内存分配器，内部针对小块内存的分配进行了优化。这类分配器会按照一组预
置的大小规格把内存页划分成块，然后把不同规格的内存块放入对应的空闲链表中，如图8-1所
示。这些内存块通常有 8 字节、 16 字节、 24 字节、 32 字节、 48 字节，直到数十或数百KB，总共几十
种大小规格。为了提高内存的利用率，这些规格大小并不都是 2 的整数次幂。程序申请内存的时候
分配器会先根据要申请的空间大小找到最匹配的规格，然后从对应的空闲链表中分配一个内存块。

图8-1 tcmalloc内存分配器预置不同规格的链表

假如想要分配一段 20 字节大小的内存，分配器会认为所有预置的规格中 24 字节这个大小最为匹配，
因此最终会实际分配一个大小为 24 字节的内存块。虽然不可避免地存在一定的空间浪费，但是解决
了内存碎片化问题，还带来了一定程度上的性能提升。这些预置规格大小的选择，结合编程语言自
身的特点，能够进一步提高内存空间的利用率。

在Go源代码runtime包的sizeclasses.go文件中，给出了一组预置的大小规格。在runtime版本1.8～
1.15期间，一直是 66 种规格，其中最小的是 8 字节，最大的是32KB。Go 1.16版本新增了 24 字节大小
这个规格，总共达到 67 种，如表8-1所示。

表8-1 sizeclasses预置的大小规格

续表
第一列是所谓的sizeclass，实际上就是所有规格按空间大小升序排列的序号。第二列是规格的空间
大小，单位是字节。第三列表示需要申请多少字节的连续内存，目的是保证划分成目标大小的内存
块以后，尾端因不能整除而剩余的空间要小于12.5%。Go使用 8192 字节作为页面大小，底层内存分
配的时候都是以整页面为单位的，所以第三列都是 8192 的整数倍。第四列是第三列与第二列做整数
除法得到的商，第五列则是余数，分别表示申请的连续内存能划分成多少个目标大小的内存块，以
及尾端因不能整除而剩余的空间，也就是在内存块划分的过程中浪费掉的空间。最后一列就有点意
思了，表示的是最大浪费百分比，结合了内存块划分时造成的尾端浪费和内存分配时向上对齐到最
接近的块大小造成的块内浪费。

对于最大浪费百分比这一列，我们举两个例子计算并验证一下。先以大小为 8 字节的内存块为例，
申请一个页也就是 8192 字节内存，可以划分成 1024 个块，因为没有余数，所以不存在尾端浪费。等
到分配内存时，浪费最严重的情况是想要分配 1 字节时，向上对齐到 8 字节会浪费掉7/8，也就是
87.5%。再来看一个块划分时不能整除的情况，例如大小为 1408 的内存块，申请两个页面也就是
16384 字节的内存，划分成 11 个内存块后剩余 896 字节。分配某个大小的内存时， 1281 ～ 1408 字节这
个范围会被向上对齐到 1408 字节这个内存块大小，其中 1281 字节是浪费最严重的情况。假如划分的
11 个内存块实际上都用作 1281 字节大小的分配，加上尾端的 896 字节，最大浪费百分比＝（（1408-
1281 ）×11+896）/16384，约等于14%。

关于sizeclasses就先介绍到这里，事实上，Go语言runtime中的sizeclasses.go文件是被程序生成出来
的，源码就在mksizeclasses.go文件中，感兴趣的读者可以从源码中了解更多细节。

8.1.2 heapArena

Go语言的runtime将堆地址空间划分成多个arena，在amd64架构的Linux环境下，每个arena的大小是
64MB，起始地址也是对齐到64MB的。每个arena都有一个与之对应的heapArena结构，用来存储

arena的元数据，如图8-2所示。

图8-2 area与heapArena的关系

heapArena是在Go的堆之外分配和管理的，其结构定义的代码如下：

bitmap字段是个位图，它用两个二进制位来对应arena中一个指针大小的内存单元，所以对于64MB
大小的arena来讲，heapArenaBitmapBytes的值是64MB/8/8×2＝2MB，这个位图在GC扫描阶段会被
用到。bitmap第一字节中的 8 个二进制位，对应的就是arena起始地址往后 32 字节的内存空间。用来
描述一个内存单元的两个二进制位当中，低位用来区分内存单元中存储的是指针还是标量， 1 表示
指针， 0 表示标量，所以也被称为指针/标量位。高位用来表示当前分配的这块内存空间的后续单元
中是否包含指针，例如在堆上分配了一个结构体，可以知道后续字段中是否包含指针，如果没有指
针就不需要继续扫描了，所以也被称为扫描/终止位。为了便于操作，一个位图字节中的指针/标量
位和扫描/终止位被分开存储，高 4 位存储 4 个扫描/终止位，低 4 位存储 4 个指针/标量位。

例如在arena起始处分配一个slice，slice结构包括一个元素指针、一个长度及一个容量，对应的
bitmap标记如图8-3所示。bitmap位图第一字节第 0 ～ 2 位标记slice 3个字段是指针还是标量，第 4 ～ 6
位标记 3 个字段是否需要继续扫描。

图8-3 arena起始处分配一个slice对应的bitmap标记

spans数组用来把当前arena中的页面映射到对应的mspan，暂时先认为一个mspan管理一组连续的内
存页面，8.1.3节中会详细介绍mspan。pagesPerArena表示arena中共有多少个页面，用arena大小
（64MB）除以页面大小（8KB）得到的结果是 8192 ，也就是每个arena中有 8192 个页面。如图8-4所
示，用给定地址相对arena起始地址的偏移除以页面大小，就可以得到对应页面在arena中的序号，
将该序号用作spans数组的下标，就可以得到对应的mspan了。

pageInUse是个长度为 1024 的uint8数组，实际上被用作一个 8192 位的位图，通过它和spans可以快速
地找到那些处于mSpanInUse状态的mspan。虽然pageInUse位图为arena中的每个页面都提供了一个
二进制位，但是对于那些包含多个页面的mspan，只有第 1 个页面对应的二进制位会被用到，标记
的是整个span。如图8-5所示，arena起始第一页对应的mspan只包含了一个页面，对应pageInUse位
图第 0 位为 1 。第二页对应的mspan包含了连续的两个页面，对应pageInUse第 1 位被使用，记为 1 。接
下来第四页至第六页对应一个mspan，在pageInUse位图中只有第四页对应的位被标记为 1 。

图8-4 arena中的页面到mspan的映射

图8-5 pageInUse位图标记使用中的span

pageMarks表示哪些span中存在被标记的对象，与pageInUse一样用与起始页面对应的一个二进制位
来标记整个span。在GC的标记阶段会原子性地修改这个位图，标记结束之后就不会再进行改动
了。清扫阶段如果发现某个span中不存在任何被标记的对象，就可以释放整个span了。

pageSpecials又是一个与pageInUse类似的位图，只不过标记的是哪些span包含特殊设置，目前主要
指的是包含finalizers，或者runtime内部用来存储heap profile数据的bucket。

checkmarks是一个大小为1MB的位图，其中每个二进制位对应arena中一个指针大小的内存单元。当
开启调试debug.gccheckmark的时候，checkmarks位图用来存储GC标记的数据。该调试模式会在
STW的状态下遍历对象图，用来校验并发回收器能够正确地标记所有存活的对象。

zeroedBase记录的是当前arena中下个还未被使用的页面的位置，相对于arena起始地址的偏移量。页
面分配器会按照地址顺序分配页面，所以zeroedBase之后的页面都还没有被用到，因此还都保持着
清零的状态。通过它可以快速判断分配的内存是否还需要进行清零。

1 ． arenaHint

Go的堆是动态按需增长的，初始化的时候并不会向操作系统预先申请一些内存备用，而是等到实
际用到的时候才去分配。为避免随机地申请内存造成进程的虚拟地址空间混乱不堪，我们要让堆区
从一个起始地址连续地增长，而arenaHint结构就是用来做这件事情的，它提示分配器从哪里分配内
存来扩展堆，尽量使堆按照预期的方式增长，该结构的定义代码如下：

图8-6 两段可用区间通过arenaHint链表表示

addr是可用区间的起始地址，down表示向下增长。当down为false时，addr表示可用区间的低地址，
类似数学上的左闭区间。当down为true时，addr表示可用区间的高地址，类似数学上的右开区间。
arenaHint只给出了起始地址和增长方向，但没有给出可用空间的结束地址。next用来指向链表中的
下一个arenaHint，sysAlloc（）函数根据当前arenaHint的指示来扩展堆空间，当申请内存遇到错误
时会自动切换至下一个arenaHint。图8-6给出了两个向不同方向增长的arenaHint构成的链表。

2 ． arenaIdx

在amd64架构的Linux环境下，arena的大小和对齐边界都是64MB，所以整个虚拟地址空间都可以看

作由一系列arena组成的。如图8-7所示，arena区域的起始地址被定义为常量arenaBaseOffset。用一
个给定的地址p减去arenaBaseOffset，然后除以arena的大小heapArenaBytes，就可以得到p所在arena
的编号。反之，给定arena的编号，也能由此计算出arena的地址。相关计算的代码如下：

图8-7 地址与arena编号之间的换算

其中，arenaIdx类型底层是个uint，它的主要作用是用来寻址对应的heapArena。在amd64架构上虚
拟地址的有效位数是 48 位，arena的大小是64MB，即 26 位，两者相差 22 位，也就是说整个地址空间
对应4MB个arena。我们已经知道每个arena都有一个对应的heapArena结构，如果用arena的编号作为
下标，把所有heapArena的地址放到一个数组中，则这个数组将占用32MB空间。32MB还可以接
受，但是在某些系统上就不止32MB了，在amd64架构的Windows上，受系统原因影响，arena的大
小是4MB，缩小了 16 倍，用来寻址heapArena的数组就会相应地变大 16 倍，那就无法接受了，所以
Go的开发者把arenaIdx分成了两段，把用来寻址heapArena的数组也做成了两级，有点类似于两级
页表，代码如下：

在Linux系统上，arenaL1Bits被定义为 0 ，而在amd64架构的Windows系统上被定义为 6 。第二级的位
数等于虚拟地址有效位数 48 减去arena大小对应的位数和第一级的位数，在amd64架构下，
arenaL2Bits在Linux系统上是 22 ，在Windows系统上是 20 。再来看一下用来寻址heapArena的数组，
它就是mheap结构的arenas字段，代码如下：

在Linux系统上，第一维数组的大小为 1 ，相当于没有用到，只用到了第二维这个大小为4M的数
组，arenaIdx全部的 22 位都用作第二维下标来寻址，如图8-8所示。

图8-8 Linux系统上用来寻址heapArena的二维数组

在Windows系统上，第一维数组的大小为64M，第二维大小为1M，因为两级都存储了指针，利用
稀疏数组按需分配的特性，可以大幅节省内存。arenaIdx被分成两段，高 6 位用作第一维下标，低 20
位用作第二维下标，如图8-9所示。

图8-9 Windows系统上用来寻址heapArena的二维数组

3 ． spanOf

至此，我们知道了如何根据一个给定的地址找到它所在的mspan。假设给定地址p，先用p减去堆区
的起始地址，再除以arena的大小，就可以得到对应的arenaIdx，如图8-7所示。进一步如图8-8与图
8-9所示，通过二维数组arenas得到heapArena的地址。再用p对arena的大小取模得到p在arena中的偏
移量，然后除以页面大小，就可以得到对应页面的序号，将该序号用作spans数组的下标，就可以
得到mspan的地址了，如图8-4所示。

在runtime中提供了一些函数，专门用来根据给定的地址查找对应的mspan，其中最常用的就是
spanOf（）函数。该函数在进行映射的同时，还会校验给定的地址是不是一个有效的堆地址，如果
有效就会返回对应的mspan指针，如果无效则返回nil，函数的代码如下：

第 1 个最外层的if负责校验arenaIdx有没有越界，例如在amd64架构上，arenas数组是按照 48 位有效地
址位来分配的，而程序代码中的地址被扩展到了 64 位，所以要经过校验才能保证安全。第 2 个最外
层的if用来判断稀疏数组第二维的某个数组是否被分配，避免遇到空指针。最后一个if检测的是对
应的arena是否已经分配，对于未分配的arena，与之对应的heapArena也不会被分配，所以指针为
空。runtime中还有一个spanOfUnchecked（）函数，与spanOf（）函数功能类似，只不过移除了与
安全校验相关的代码，需要调用者来保证提供的是一个有效的堆地址，函数的代码如下：

本节关于arena相关的分析就到这里，期间我们多次提到了mspan，8.1.3节中将围绕mspan进行一些
分析探索。

8.1.3 mspan

mspan用来记录和管理一组连续的内存页，这段连续的内存通常会被按照某个sizeclass划分成等大
的内存块，内存块的分配及GC的标记和清扫都是在mspan层面完成的。除了自动管理模式之外，
mspan也支持手动管理模式。和heapArena一样，mspan也是在堆之外单独分配的。在进一步分析探
索之前，我们还是先来看一下mspan的数据结构，代码如下：

next和prev用来构建mspan双链表，list指向双链表的链表头。startAddr指向当前span的起始地址，因
为span都是按整页面分配的，所以指向的是首个页面的地址。npages记录的是当前span中有几个页
面，乘以页面大小就可以得到span空间的大小。manualFreeList是个单链表，在mSpanManual类型的
span中，用来串联所有空闲的对象。类型gclinkptr底层是个uintptr，它把每个空闲对象头部的一个
uintptr用作指向下一个对象的指针，如图8-10所示。

nelems记录的是当前span被划分成了多少个内存块。freeindex是预期的下个空闲对象的索引，取值
范围在 0 和nelems之间，下次分配时会从这个索引开始向后扫描，假如发现第N个对象是空闲的，
就将其用于分配，并会把freeindex更新成N+1。allocBits和gcmarkBits分别指向当前span的分配位图
和标记位图，其中每个二进制位对应span中的一个内存块，如图8-11所示。给定当前span中一个内
存块的索引n，如果n>＝freeindex并且allocBits[n/8]&（1<<（n%8））＝ 0 ，则该内存块就是空闲
的。

图8-10 gclinkptr串联的对象

图8-11 allocBits位图对应span中已分配和未分配的内存块

清扫阶段会释放旧的allocBits，然后把gcmarkBits用作allocBits，并为gcmarkBits重新分配一段清零
的内存。allocCache缓存了allocBits中从freeindex开始的 64 个二进制位，这样一来在实际分配时更高
效。sweepgen与mheap.sweepgen相比较，能够得知当前span处于待清扫、清扫中、已清扫等哪种状
态。divMul、baseMask、divShift、divShift2都是用来优化整数除法运算的，转换成乘法运算和位运
算后更高效。allocCount用于记录当前span中有多少内存块被分配了。spanclass类似于sizeclass，实
际上它把sizeclass左移了一位，用最低位记录是否不需要扫描，称为noscan，如图8-12所示。Go为
同一种sizeclass提供了两种span，一种用来分配包含指针的对象，另一种用来分配不包含指针的对
象。这样一来不包含指针的span就不用进一步扫描了，noscan位就是这个意思。

图8-12 spanclass中sizeclass和noscan位的位置

state记录的是当前span的状态，有mSpanDead、mSpanInUse和mSpanManual这 3 种取值，分别表示
无效的mspan、被GC自动管理的span和手动管理的span。goroutine的栈分配用的就是mSpanManual
状态的span。needzero表明分配之前需要对内存块进行清零。elemsize是内存块的大小，可以通过
spanclass计算得到。limit记录的是span区间的结束地址，为右开区间。specials是个链表，用来记录
添加的finalizer等，speciallock用来保护这个链表。

1 ． nextFreeIndex （）方法

在了解了mspan各个字段的大致作用之后，我们再来分析一个重要的方法nextFreeIndex（），这个
方法的作用是寻找下一个空闲的索引，在实际分配内存的时候会用到它，该方法的源代码如下：

按照代码中的空行，可以把整个函数的逻辑分成三部分。第一部分只是做了些简单的校验，当
freeindex等于nelems时，表明当前span中已经没有空闲的空间了。freeindex是不能大于nelems的，
如果free index大于nelems，就意味着堆已经被破坏了，遇到这种不可恢复的错误，程序需要尽快崩
溃。

第二部分的逻辑是寻找下个空闲索引，利用allocCache批量缓存allocBits能够提升效率。需要注意，
allocCache中用 0 表示已分配，用 1 表示未分配，这点与allocBits是相反的，主要是为了方便通过
Ctz64（）函数统计尾端为 0 的二进制位数量。如果Ctz64（）函数的返回值是 64 ，说明allocCache中
缓存的索引都被分配了，那就向后移动freeindex，并通过refillAllocCache（）方法重新填充
allocCache，这个填充是按照 64 位对齐的。通过freeindex和对应的二进制位在allocCache中的偏移相
加，就可以得到下个空闲索引，但是一定要判断有没有越界。allocBits因为要和allocCache配合，所
以是按照 64 位的整倍数来分配的，但是nelems并不一定能被 64 整除，allocBits的位数是在nelems的
基础上基于 64 做的向上对齐，所以尾部可能有一部分二进制位是无效的。

第三部分是分配后的调整工作，需要把freeindex指向分配后的下一个位置，allocCache也要相应地
进行移位处理。如果此时freeindex能够被 64 整除，就说明allocCache缓存的二进制位都已经用完
了，如果freeindex不等于nelems，也就是说当前span还有剩余空间，此时需要重新填充allocCache。
最后，返回找到的空闲索引，函数返回后该索引也就被分配了。

现在回过头来看arena和span，heapArena层面实现了从堆地址到mspan的快速映射，并且为每个指针
大小的内存单元提供了位图，这个位图能够用来区分指针和标量，以及确定要继续扫描还是应该终
止，便于GC标记的时候高效地读取。span层面实现了细粒度内存单元的管理，与arena层面提供的
位图不同，mspan中的分配位图和GC标记位图都是针对内存单元的，内存单元依据sizeclass指定的
大小划分而成，而不是按照指针大小来提供的。heapArena和mspan中的位图，因为用处不一样，所
以分别适合放在不同的地方。

2 ． setSpans

具体的span分配逻辑在mheap的allocSpan（）方法中，只不过代码篇幅有些长，就不进行详细分析
了，这里只简单分析一下主要逻辑。allocSpan（）方法最主要的工作可以分成 3 步，第一步分配一
组内存页面，第二步分配mspan结构，第三步设置heapArena中的spans映射。内存页面和mspan都有
特定的分配器，这里不再进一步展开，重点关注一下第三步。mheap有个setSpans（）方法，专门
用来把一个给定的span映射到相关的heapArena中，该方法的源代码如下：

参数base给出了span这段内存的起始地址，npage给出了页面跨度，s是用来管理这个span的mspan结
构。setSpans先根据base地址找到第 1 个heapArena，然后以页面为单位循环设置spans映射。当检测
到达arena边界时，就会切换到下一个arena，说明span可以跨arena，如图8-13所示。

图8-13 跨arena的span示例

8.1.4 mcentral

在8.1.2节和8.1.3节中，我们了解了arena和span，arena中可以有多个不同sizeclass的span，将给定的
地址经过heapArena.spans的映射，可以得到所属的mspan，这在GC标记的时候非常有用。只不过我
们在分配内存的时候，需要根据sizeclass来找到对应的mspan，由于arena做不到这一点，因此，堆
中引入了mcentral，可以先简单地把它理解成对应各种sizeclass的一组mspan空闲链表。在mheap中
定义了一个mcentral的数组，代码如下：

图8-14 mheap中的mcentral数组结构示意图

其中numSpanClasses是个值为 136 的常量，它是由（67+1）×2得来的。 67 种sizeclass再加上一个大小
为 0 的sizeclass，然后乘以二是因为一份包含指针，另一份不包含指针，也就是noscan位，如图8-14
所示。之所以不是直接基于mcentral的数组，而要再包一层struct，是为了使用pad来对齐到cache
line大小，这样一来每个mcentral中的锁都在自己的cache line中。

一个mcentral类型的对象，对应一种spanClass，管理着一组属于该spanClass的mspan。mcentral的结
构定义代码如下：

spanclass字段记录了当前mcentral管理着哪种类型的mspan。partial和full是两个spanSet数组，
spanSet有自己的锁，是个并发安全地支持push和pop的*mspan集合。partial中都是还没有分配完的
span，每个span至少包含一个空闲单元，full中都是没有空闲空间的span。这两个字段为什么都是数
组呢？数组中的两个spanSet，有一个包含的是已清扫的span，另一个包含的是未清扫的span，并且
它们在每轮GC中会互换角色。

mheap中的mcentral数组实现了全局范围的、基于spanClass的mspan管理。因为是全局的，所以需要
加锁。为了进一步减少锁竞争，Go把mspan缓存到了每个P中，这就是8.1.5节中我们要了解的
mcache。mcentral提供了两个方法用来支持mcache，一个是cacheSpan（）方法，它会分配一个span
供mcache使用，另一个是uncacheSpan（）方法，mcache可以通过它把一个span归还给mcentral。这
里不再分析这两个方法的代码，感兴趣的读者可自行查看。

8.1.5 mcache

在Go的GMP模型中，mcache是一个per-P的小对象缓存。因为每个P都有自己的一个本地mcache，
所以不需要再加锁。mcache结构也是在堆之外由专门的分配器分配的，所以不会被GC扫描。
mcache的结构定义代码如下：

nextSample是配合memory profile来使用的，当开启memory profile的时候，每分配nextSample这么多
内存后，就会触发一次堆采样。scanAlloc记录的是总共分配了多少字节scannable类型的内存，也就
是noscan位为 0 、可以包含指针的span。tiny和tinyoffset用来实现针对noscan型小对象的tiny
allocator，tiny用来指向一个 16 字节大小的内存单元，tinyoffset记录的是这个内存单元中空闲空间的
偏移量。tiny allocator能够将一些小对象合并分配，极大地提高了空间利用率。tinyAllocs记录的是
共进行了多少次tiny分配。alloc是根据spanClass缓存的一组mspan，因为不需要加锁，所以不用像
mcentral那样对齐到cache line。stackcache是用来为goroutine分配栈的缓存，我们在第 9 章中将具体
介绍栈内存的管理。flushGen记录的是上次执行flush时的sweepgen，如果不等于当前的sweepgen，
就说明需要再次flush以进行清扫。

8.1.6 mallocgc

我们在8.1.1～8.1.5节中了解了与堆内存管理相关的一系列数据结构，还有几个比较关键的底层函
数，了解这些都是为了能够更好地理解本节要介绍的mallocgc（）函数。本节之初已经讲过，
mallocgc（）函数是堆分配的关键函数，runtime中的new系列函数和make系列函数都依赖于它。该
函数的代码稍微有点长，完全贴出来既占用篇幅又不好分析，但是要完全不看代码又有种脱离实际
的感觉，所以我们先大致讲一下函数的主要逻辑，再把关键代码分段进行细化分解。

mallocgc（）函数的主要逻辑按照代码的先后顺序可以分成如下几部分：

（ 1 ）检查当前goroutine的gcAssistBytes值，如果减去本次要分配的内存大小后结果为负值，就需要
先调用gcAssistAlloc（）函数辅助GC完成一些标记任务。

（ 2 ）根据此次要分配的空间大小，以及是否要分配noscan类型空间，选用不同的分配策略。目前
有 3 种分配策略，即tiny、sizeclass和large。

（ 3 ）如果分配的不是noscan类型空间，就需要调用heapBitsSetType（）函数，该函数会根据传入
的类型元数据对heapArena中的位图进行标记。

（ 4 ）调用publicationBarrier、GC标记新分配的对象、memory profile采样、更新gcAssistBytes的
值，按需发起GC等一系列收尾操作。

1 ．辅助 GC

辅助GC也就是mallocgc（）函数的第一部分，对应的源代码如下：

其中gcBlackenEnabled就像是一个开关，它在GC标记开始的时候被设置为 1 ，在标记结束的时候被
清零，也就是只有在GC标记阶段才能执行辅助GC。每个goroutine都有自己的gcAssistBytes，在这
个值用光之前不用执行辅助GC。辅助GC机制能够有效地避免程序过快地分配内存，从而造成GC
工作线程来不及标记的问题。

2 ．空间分配

空间分配指的是上述mallocgc（）函数的 4 个阶段中的第二阶段，这里会根据要分配的目标大小及
是否为noscan型空间，来选用不同的分配策略。这里先来看一下是如何选择策略的，然后针对每种
策略展开分析。选择分配策略的代码如下：

maxSmallSize是个值为 32768 的常量，也就是说对于32KB以上的内存分配会直接根据需要的页面数
分配一个新的span。maxTinySize是个值为 16 的常量，对于小于 16 字节且是noscan类型的内存分配请
求会使用tiny分配器。对于[16，32768]这个范围内的noscan分配请求，以及不超过 32768 的所有
scannable型分配请求都会使用预置的各种sizeclass来分配。

接下来我们先来看一下tiny allocator是如何分配空间的，相关代码如下：

先取出mcache中的tinyoffset，然后根据分配目标大小size进行对齐，如果对齐后的off加上size没有
超过maxTinySize，就可以使用现有的tiny内存块直接分配。maxTinySize是常量 16 ，也就是tiny
allocator内部内存块的大小。如果当前内存块中剩余的空间不足以满足本次分配，就从mcache的
alloc数组中找到对应tinySpanClass的mspan，并通过nextFreeFast（）函数重新分配一个 16 字节的内
存块。如果对应的mspan中也没有空间了，nextFree（）方法会从mcentral中取一个新的mspan过
来，并且返回值shouldhelpgc是true。最后，把新分配的内存块清零，如果本次分配之后新内存块的
剩余空间大于旧内存块的剩余空间，就用新的把旧的替换掉。

tiny分配器被设计成能够将几个小块的内存分配请求合并到一个 16 字节的内存块中，这样能够提高
内存空间的利用率。例如，通过tiny分配器分配 16 个 1 字节的内存，合并分配后利用率为100%，如
图8-15所示。

图8-15 使用tiny分配器连续分配 16 次 1 字节内存

如果没有tiny分配器，则每次分配 1 字节就需要适配sizeClass中最小的规格，即 8 字节，而且每次都
会浪费 7 字节，内存实际利用率仅为12.5%，如图8-16所示。

图8-16 适配sizeClass连续分配 16 次 1 字节内存

再来看一下使用预置的sizeclass来分配内存的情况，相关源代码如下：

smallSizeMax是个常量，值是 1024 。 1024 减去 8 是 1016 ，也就是当size不超过 1016 时使用
size_to_class8，否则使用size_to_class128将size映射到对应的sizeclass，然后结合noscan合成spc，并
通过spc找到alloc数组中对应的mspan，再通过nextFreeFast（）函数分配内存块。如果mspan中也没
有剩余空间，就调用nextFree（）方法去mcentral中取一个新的mspan。最后按需清空内存块。

当要分配的内存空间超过32KB时，就要直接分配内存页面了，具体代码如下：

allocLarge（）方法会把size向上对齐到整页面大小，然后分配一个大的span。最后，整个span被用
作一个内存块返回给请求者。至此，空间分配逻辑也就梳理完了。

3 ．位图标记

分配完空间之后，需要对heapArena中的位图进行标记，这个工作是由heapBitsSetType（）函数完
成的。除此之外，还会把分配了多少需要扫描的空间累加到scanAlloc字段，具体代码如下：

如果分配的是noscan类型的空间，就可以跳过这一步了。计算scanSize的时候，用到了类型元数据
中的ptrdata字段，它表示该类型的数据前多少字节中包含指针，后续还有数据也属于标量数据，只
扫描前ptrdata字节就可以了。

4 ．收尾工作

最后的收尾工作也包含多个操作，首先调用publicationBarrier（）函数，该函数相当于一个Store-
Store屏障，在x86上根本用不着，所以被实现成一个空的函数，但在其他一些平台上有实际效果。
在此之后要让GC标记新分配的对象，具体代码如下：

上述代码先进行了判断，只有在GC的标记阶段才能标记新分配的对象。在此之后Memory Profile的
采样代码如下：

在Memory Profile开启的情况下，每分配nextSample字节内存以后，就进行一次采样。之后还剩最
后一步GC相关操作，代码如下：

在分配的过程中，size可能已向上对齐过，所以可能会变大，而dataSize保存了原来真实的size值，
最后要从分配内存的goroutine的gcAssistBytes中减去因size对齐而额外多分配的大小。最后执行检
测操作，如果达到了GC的触发条件，就发起GC。

至此，关于堆内存分配的探索就先告一段落。本节中，我们了解了内置的sizeclasses和用来管理堆
空间的arena，以及负责小块内存管理的span，分析了将堆地址映射到对应mspan的过程，以及
mspan如何寻找下一个空闲的内存块。还有集中管理mspan的mcentral，和per-P缓存mspan的
mcache。在本节的最后，分析了mallocgc（）函数的主要逻辑，了解了tiny、sizeclasses和large这 3
种内存分配策略，应该可以让各位读者理解堆内存分配的大致框架。

8.2 垃圾回收
垃圾回收器也就是我们通常所讲的GC，Go语言的垃圾收集器是基于精确类型的，并且被设计成可
以与普通的线程并发运行，同时允许多个GC线程并行运行。它是一个使用写屏障的并发标记清除
算法，是不分代的、不压缩的。一轮垃圾回收包含以下几个步骤：

（ 1 ）Sweep Termination，清扫终止，在本轮标记开始之前，先把上一轮剩余的清扫工作完成。具
体来讲，首先Stop the World，从而使所有的P都达到一个GC安全点，然后清扫所有还未清扫的
span，通常情况下不会存在还未清扫的span，除非GC提前触发。

（ 2 ）Concurrent Mark，并发标记，可以认为是本轮GC的主要工作。具体来讲，将gcphase从
_GCoff改成_GCmark，启用写屏障和辅助GC，把GC root送入工作队列中。

直到所有的P都开启了写屏障后，GC才会开始标记对象，写屏障的开启也是在STW期间完成的，
然后Start the World，GC工作线程和辅助GC会一起完成标记工作，写屏障会将指针赋值过程中被覆
盖掉的旧指针和新指针同时着色，新分配的对象会被立即标为黑色。GC root包含所有协程的栈、
可执行文件数据段和BSS段等全局数据区，以及来自runtime中一些堆外数据结构里的堆指针。扫描
一个goroutine时会先将其挂起，对其栈上发现的指针进行着色，最后恢复它的运行。GC标记时，
从工作队列中取出灰色对象，扫描该对象使其变成黑色，并对发现的指针进行着色，这可能又会向
工作队列中添加更多指针。因为GC涉及多处本地缓存，所以它使用一种分布式算法来判断所有的
GC root和灰色对象都已经处理完，之后会切换至Mark Termination，即标记终止状态。

（ 3 ）Mark Termination，标记终止。Stop the World，将gcphase设置成_GCmarktermination，关闭
GC工作线程和辅助GC。冲刷所有的mcache，以将mspan还回mcentral中。

（ 4 ）Concurrent Sweep，并发清扫。将gcphase设置成_GCoff，重置清扫相关状态并关闭写屏障。
Start the World，此后分配的对象就都是白色的了，必要时，分配之前会先对span进行清扫。除了分
配时清扫之外，GC还会进行后台清扫。等到分配的内存达到一定的阈值后，又会触发下一轮GC。

如图8-17所示，在整个GC的过程中一共需要两次Stop the World，分别是在清扫终止和标记终止这
两个阶段，程序需要STW来达到一致状态，好在这两个阶段都比较短暂。在并发标记和并发清扫
阶段都允许普通goroutine和GC worker并发运行，整体上STW的占比是非常小的。

图8-17 一轮GC的几个阶段
8.2.1 GC root

所谓GC root，其实就是标记的起点。程序运行阶段内存中所有的变量、对象之间是有关联性的，
例如通过一个struct的地址可以找到这个对象，它的所有字段中如果包含指针，又可以进一步寻址
其他的变量或对象。通过指针，所有的变量和对象组成了一张大图，而GC root就是这张图的一组
起点，从这组起点出发能够遍历整张图。没错，是一组起点而不是一个，因为这张图的结构非常复
杂，有多个起点，只通过其中一两个起点不足以遍历整张图。下面我们就来看一看Go的几种GC
root，以及GC是如何扫描的。

1 ．全局数据区

全局数据区这种叫法是针对进程的内存布局来讲的。一般情况下，变量的分配位置就是全局数据
区、栈区和堆区这 3 处。堆区主要用于运行阶段的动态分配，而栈区以栈帧为单位来分配，装载的
是函数的参数、返回值和局部变量，全局数据区主要用于全局变量的分配。对应到Go语言，就是
包级别的变量，此处全局的含义应该理解为与进程生命周期相同，而不是语法层面的作用域。在可
执行文件中有两个节区可以被认为是全局数据区，一个是data段，里面都是有初始值的变量，另一
个是bss段，里面是未初始化的变量。事实上，bss段在可执行文件中不会被实际分配空间，只是有
个对应的header来描述它。在可执行文件加载的时候，加载器会为bss段分配空间，如图8-18所示。

全局数据区中的变量分配在构建阶段就已经确定了，在运行阶段有可能包含指向堆区的指针，所以
需要把它作为GC root进行扫描。如何进行扫描呢？如果再逐个分析每个变量的类型元数据，效率
就太低了，毕竟我们只关心其中是否包含指针而已。好在构建工具已经把供GC使用的位图写入了
可执行文件中，通过moduledata的gcdatamask和gcbssmask字段就可以直接使用了，其中每一位对应
全局数据区中的一个指针大小的内存块，实际上就是个指针位图，如图8-19所示。

2 ．栈

这里指的是所有goroutine的栈，以及与栈密切相关的_defer、_panic这些对象。因为goroutine是活动
的，会分配内存、进行指针赋值等操作，所以栈上往往会有大量指向堆内存的指针，_defer和
_panic对象里也有一些指针字段，GC在对栈进行扫描时会一并处理。与全局数据区类似，栈扫描
时也需要知道哪些是指针，所以需要获得与每个栈帧对应的指针位图，如图8-20所示，
runtime.getStackMap（）函数能够返回目标栈帧的局部变量和参数的指针位图，以及栈帧上的对象
列表。

图8-18 可执行文件加载时为bss段分配空间

图8-19 gcdatamask是标记全局数据区的指针位图

3 ． Finalizer

通过runtime.SetFinalizer（）函数能够为堆上分配的对象关联一个finalizer（）函数，当GC发现了一
个关联了finalizer（）函数的不可达对象时，它就会取消它们之间的关联，并在一个特有的协程中
用该对象的地址作为参数来调用finalizer（）函数。这样一来就会使该对象再次变成可达的，只是
不再有与之关联的finalizer（）函数了，这样下一轮GC就会发现它不可达，进而把它清理掉。

图8-20 每个栈帧都有对应的指针位图
Finalizer为什么也属于GC root呢？事实上，从该对象可到达的所有内容都必须被标记，对象自身却
不需要。因为我们需要保证，在把对象的地址作为参数调用与它关联的finalizer（）函数时，通过
该对象可到达的所有内容都被保留了下来，否则就会发生意料之外的错误。与对象关联的
finalizer（）函数使用一个specialfinalizer结构来存储，该结构的定义代码如下：

specialfinalizer对象不是在堆上分配的，因此其中的一些指针字段也需要扫描，主要是指向funcval
的指针，因为这个Function Value本身可能是一个在堆上分配的闭包对象，如图8-21所示。

8.2.2 三色抽象
Go语言的GC使用了三色抽象标记堆中的对象，使用的 3 种不同颜色及其含义如表8-2所示。

图8-21 标记关联有finalizer的对象

表8-2 三色抽象的颜色及其含义

每轮GC标记开始时，所有对象都是白色的，标记过程中 3 种颜色的对象都会存在，标记结束时只剩
下黑色和白色的对象。在并发清理阶段会清理掉那些白色对象，因为新分配的对象也是白色的，所
以要先将整个span清理后才能用于新的分配。

GC的工作队列实现了灰色对象指针的生产者——消费者模型，灰色对象实际上是一个被标记并且
被添加到工作队列中等待扫描的对象，黑色对象同样也被标记过，但是不在工作队列中。如图8-22
所示，写屏障、GC root扫描、栈扫描和对象扫描都会向工作队列中添加更多指针，扫描工作会消
费工作队列中的灰色指针，使它们变成黑色并扫描它们，可能又会产生更多灰色指针。

图8-22 工作队列的生产者——消费者模型
在runtime中GC工作队列的具体实现就是gcWork这个结构体类型，结构的定义代码如下：

其中wbuf1和wbuf2分别是主要和次要工作缓冲区。bytesMarked记录了通过当前工作队列标记了多
少内存空间，最终会被聚合到全局的work.bytesMarked中。scanWork记录了当前工作队列执行了多
少扫描工作，也是以字节为单位的。flushedWork表示从上次gcMarkDone检测之后，有非空的工作
缓冲区被冲刷到了全局的工作列表中，与标记终止的判定有关。

工作缓冲区对应的workbuf结构，以及workbuf内嵌的workbufhdr结构的定义代码如下：

其中的obj是个uintptr数组，用来存储扫描过程中发现的指针。nobj用于记录obj数组使用了多少，实
际上是个递增的下标，为 0 时表示缓冲区是空的，等于obj的长度时表示缓冲区已满。lfnode的类型
是个结构体类型，包含一个int64和一个uintptr，可以简单地认为它用来构建链表，包含指向下一个
节点的指针。_WorkbufSize的值是 2048 ，所以数组obj的容量应该是 253 。

实际为堆对象着色的工作是runtime中的greyobject（）函数实现的，以下就是笔者精简过的函数源
码，去掉了与调试相关的部分代码，保留了最主要的逻辑，代码如下：

第 1 个if语句用于校验对象地址是不是按照指针对齐的，8.1节讲内存分配的时候已经知道各种
sizeclass都是 8 的整数倍。接下来调用markBitsForIndex（）方法，可以通过对象内存块在span中的
索引objIndex定位到gcmarkBits对应的二进制位，如果已经标记过了就直接返回，如果未标记就进
行标记。heapArena结构中的pageMarks记录的是哪些span中存在被标记过的对象，所以要通过它把
对象所在的span也标记一下。图8-23展示了greyobject（）方法标记对象的效果。

图8-23 greyobject标记对象

接下来的if语句用于判断对象所在的span是否为noscan型，也就是不包含指针，那样就不用进一步
对对象进行扫描了，记录bytesMarked后直接返回，对象obj就是黑色的了。如果span不是noscan型
的，就把对象指针添加到工作队列中，等待后续进一步对对象展开扫描。

8.2.3 写屏障
GC使用写屏障来追踪指针的赋值操作，Go使用的是一种组合了删除写屏障和插入写屏障的混合写
屏障。删除写屏障负责对地址被覆盖掉的对象进行着色，插入写屏障负责对新地址指向的对象进行
着色。在goroutine的栈是灰色的时候，才有必要执行插入写屏障。按照这种设计思想，混合写屏障
的伪代码如下：

其中slot是个指向指针的指针，也就是指针赋值运算中目的操作数的地址，ptr是用来赋值的新值。
shade（）函数会根据传入的地址标记堆上的对象，还会把该地址添加到GC工作队列中，前提是传
入的是一个堆地址。混合写屏障能够防止goroutine对GC隐藏某个对象：

图8-24 示例初始状态G栈帧已完成扫描
（ 1 ）shade（*slot）能够防止goroutine把指向对象的唯一指针从堆或全局数据段移动到栈上，从而
造成对象被隐藏，当goroutine尝试删除一个堆上的指针时，删除写屏障负责为该指针指向的对象着
色。

例如，当前协程G的栈已经完成扫描，A和B是栈上的两个指针，如图8-24所示。

接下来G会执行如下操作：

①把old的地址写入栈上的本地变量A。

②把ptr的地址写入slot。

上述第一步操作因栈上没有插入写屏障，不会标记old指针，如果堆上没有删除写屏障，指向old的
唯一路径被切断，old就不能被GC发现了，如图8-25所示。

所以在删除堆上的指针时应用删除写屏障对old进行标记，如图8-26所示。

（ 2 ）shade（ptr）能够防止goroutine把指向对象的唯一指针从它的栈上移动到堆或全局数据段的某
个黑色对象里而造成的隐藏问题，当goroutine尝试向一个黑色对象里写入指针时，插入写屏障负责
为该指针指向的对象着色。

图8-25 堆上没应用删除写屏障时old被隐藏

图8-26 堆上应用删除写屏障对old进行标记

例如，当前协程G的栈还未扫描，A和B是栈上的两个指针，堆上的slot和old是在标记期间分配的，
所以都已被标记为黑色，之前分配的ptr还是白色，如图8-27所示。

接下来G会执行如下操作：

①把ptr的地址写入slot。

②把old的地址写入B。

上面第二步操作在栈上没有删除写屏障，不会标记ptr。如果没有插入写屏障，就会将白色对象ptr
写入堆上的黑色对象slot，此时ptr就不能被GC发现了，如图8-28所示。

图8-27 示例初始状态G栈帧还未扫描
图8-28 没应用插入写屏障时ptr被隐藏

为了避免将白色对象写入堆上的黑色对象，就要靠插入写屏障，在写入slot时标记新指针ptr，如图
8-29所示。

图8-29 堆上应用插入写屏障对ptr进行标记

（ 3 ）如果goroutine的栈是黑色的，则shade（ptr）就没有必要了。因为把对象指针从栈上移动到堆
或全局数据段进而造成其隐藏的前提是，该指针在栈上时是未被标记的。栈刚刚被扫描完时，它指
向的对象都是被标记过的，所以不会有隐藏的对象指针。shade（*slot）会防止后续有指针在栈上
被隐藏。

还是直白点讲更好理解，当进入并发标记阶段以后，程序会从所有GC root开始扫描遍历整个对象
图。并发标记在设计上允许普通goroutine和GC一起运行，只是在扫描goroutine栈的时候会暂时将
其挂起，扫描完成后又会恢复运行。goroutine恢复运行之后可能又会对整个对象图进行一系列修
改，主要是新分配内存和移动现有指针（指针赋值），标记阶段分配的内存都会被mallocgc（）函
数直接标黑，所以不会有遗漏，但是指针赋值会有较多变数。我们不能重新扫描整个对象图，只想
处理后来的增量变动，而写屏障就能很好地追踪到goroutine恢复运行后造成的增量变动。

因为变量一般就是存在于全局数据段、堆区和栈区，所以goroutine造成的增量变动也就脱离不了这
几处位置。如果对全局数据段、堆和栈都应用插入写屏障，则可以跟踪到所有增量修改，但是这就
要求goroutine在向全局数据段、堆及栈上写入指针时，都要经过插入写屏障。全局数据段和堆还可
以接受，如果操作当前函数栈帧中的指针都要经过插入写屏障，无论是对程序的性能还是可执行文
件的体积，都会造成很大的影响，因为编译器需要额外生成大量代码，所以我们还要寻求一种新的
方案，能够使goroutine不必对当前函数栈帧上的指针应用写屏障，这也就是Go为什么要引入混合
写屏障的原因。

首先，当为栈上的指针赋值时，新的地址值大致有 4 种来源，即全新分配、栈上的指针、堆上的指
针，以及全局数据段的指针。标记阶段全新分配的对象会被mallocgc（）函数自动标黑，所以不需
要额外处理。函数栈帧里两个指针间的赋值不必应用写屏障，因为已扫描过的栈不存在隐藏指针，
未扫描过的栈不需要追踪增量变动，后续扫描时会完整处理。至于堆和全局数据段，如果仅仅从它
们那里把指针复制到栈上，也不会有问题，我们虽然不再重新扫描栈，但是对象可以通过堆或全局
数据段里旧有的指针来保证其可达性。怕的就是我们把指针复制到栈上以后，堆或全局数据段里旧
有的指针被擦除了，而且不再有其他的指针指向该对象。栈上复制过来的指针就变成了唯一指针，
然而我们不再重新扫描栈，所以对象就被隐藏了。

至此，关键的问题就变成了，当堆或全局数据段中的指针被擦除之前，需要灰化它指向的对象。这
样一来，把堆和全局数据段里的指针复制到栈上也不用经过插入写屏障了，旧有指针不被擦除，由
旧有指针来保证可达性，旧有指针被擦除前，删除写屏障负责灰化其指向的对象。这就是Go引入
删除写屏障的原因，缘于我们不希望对栈应用插入写屏障。

插入写屏障就比较好理解了，前提还是因为我们不会重新扫描堆和全局数据段。如果当前的栈还未
被扫描，栈上就有可能存在白色的指针。如果goroutine把一个白色指针赋值给堆或全局数据段里一
个黑色对象的某个字段，并且栈上的旧有指针在栈扫描之前被覆盖，则该对象就被成功地隐藏了。
插入写屏障就是用来跟踪写入堆和全局数据段的指针，从而防止对象隐藏。

删除写屏障应对就像是一种极端条件，只有在即将被擦除的指针本身位于堆或全局数据段上，并且
是指向某个位于堆上的对象的唯一指针，并且该指针曾经被复制到某个黑色的协程栈上时，删除写
屏障才会真正发挥作用。实际实现的时候不必去跟踪或检测这些条件，只是宽泛地对堆和全局数据
段里的指针擦除进行跟踪就行了。插入写屏障也不必真地去检测goroutine的栈是否为黑色，这样会
造成一定程度的性能损失，宽泛地跟踪写入堆和全局数据段的所有指针就行了。

下面我们就用一段简单的示例代码，通过反编译的方法，来看一看写屏障是如何被应用的，示例代
码如下：

代码中的 3 个函数对应 3 种不同的场景，toStack（）函数把一个未知来源的指针复制到栈上，函数的
参数i是个int类型的指针，未知来源指的是它所指向的int类型的指针可以在栈、堆及全局数据段等
任何位置。相应地，toGlobal（）函数会把一个未知来源的指针赋值给全局数据段里的变量p，而
toUnknown（）函数则是把一个未知来源的指针复制到未知的目的地。

我们先来反编译一下toStack（）函数，按照之前的分析，它应该不会应用写屏障。反编译得到的汇
编代码如下：

只有简单的 4 条汇编指令，完成指针复制后就返回了，确实没有应用写屏障的痕迹。别着急，接下
来反编译toGlobal（）函数，按道理它应该用到写屏障，反编译得到的汇编代码如下：

汇编代码的开头和结尾是我们熟悉的栈增长代码，CMPL$0x0，runtime.writeBarrier（SB）这条指
令是在检测写屏障有没有开启，后面的CALL runtime.gcWriteBarrier（SB）指令是在调用写屏障的
处理函数。我们稍后会梳理写屏障处理函数的逻辑，toUnknown（）函数反编译后得到的汇编代码
如下：

与toGlobal（）函数的代码结构基本相同，我们又看到了CALL runtime.gcWriteBarrier（SB）指令。
总结一下反编译这 3 个函数得到的结论：把指针复制到栈上不需要写屏障，把指针赋值给全局数据
段中的变量需要写屏障。把指针复制到一个未知的位置（可能是栈、堆或全局数据段），也需要写
屏障，因为对栈上的指针应用写屏障并不会出错，不应用是为了提高性能，而堆和全局数据段则必
须用写屏障才行，否则可能造成对象隐藏而被错误地释放。

最后，我们来看一下runtime.gcWriteBarrier（）函数的逻辑，这个函数是用汇编语言实现的。在梳
理汇编代码之前，先来看一个数据结构，也就是被写屏障用作缓冲区的wbBuf结构，代码如下：

其中buf是个指针数组，wbBufEntryPointers和wbBufEntries这两个常量的值分别是 2 和 256 。因为是
删除加插入的混合写屏障，所以每次会向缓冲区中写入两个指针，而缓冲区总共可供这样写入 256
次，写入 256 次后便会写满。next指向缓冲区可用的位置，每次写入时向后移动两个指针大小。end
刚好指向缓冲区之后，可以理解为右开区间的坐标值，当next等于end时表示缓冲区满了。

接下来可以梳理gcWriteBarrier（）函数的汇编源码了，笔者在代码中添加了注释以便于理解，代
码如下：

有兴趣的读者可以返回前面反编译 3 个函数的地方，看一看编译器是如何通过DI和AX这两个寄存器
向gcWriteBarrier（）函数传递参数的，关于写屏障的探索就先到这里。

8.2.4 触发方式
Go的GC共有 3 种触发方式，第 1 种是被runtime初始化阶段创建的sysmon线程和forcegchelper协程发
起，属于基于时间的周期性触发。第 2 种是被我们刚刚分析过的mallocgc（）函数发起的，触发条
件是堆大小达到或超过了临界值。第 3 种是被开发者通过runtime.GC（）函数强制触发。通过查看
这三处源码，发现内部会调用同一个GC启动函数，这就是runtime.gcStart（）函数，函数的原型如
下：

我们不打算展开分析这个函数的源码，而是来研究一下它的参数，也就是这个gcTrigger类型，它是
一个结构体，具体的定义代码如下：

其中gcTriggerKind底层是个int类型，runtime定义了 3 个gcTriggerKind类型的常量，该常量的取值及
其含义如表8-3所示。

表8-3 gcTriggerKind的取值及其含义

gcTrigger类型提供了一个test（）方法，用于检测当前有没有达到GC触发条件，源代码如下：

1 ． gcTriggerHeap

在处理gcTriggerHeap这种类型时，memstats.heap_live是当前的堆大小，memstats.gc_trigger是控制
器计算得到的临界值。临界值来源于上次标记的堆大小和gcpercent的值，后者可以通过环境变量
GOGC进行设置，表示当堆增长超过百分之多少后触发GC，参考的堆起始大小就是上次标记终止
时标记的大小，控制器会在每次标记终止时更新临界值。那么第一次触发参考哪个值呢？因为没有
上一次可供参考，所以第一次触发的临界值被预置为4MB，在gcinit（）函数里进行初始化。

mallocgc（）函数中会发起GC的相关代码在8.1.6节已经讲解过了，如果mallocgc（）函数分配了较
大空间，则shouldhelpgc的值就是true，然后就会创建一个gcTriggerHeap类型的gcTrigger，通过test
检测当前堆大小是否达到或超过临界值，按需调用gcStart（）函数发起GC。

2 ． gcTriggerTime

当处理gcTriggerTime类型时，memstats.last_gc_nanotime以纳秒为单位记录了上次GC执行的时刻，
gcTrigger的now字段存储的是想要发起GC时的时间戳，两者之差如果超过forcegcperiod就会触发
GC。至于gcTriggerCycle这种类型，首先要说明一下work.cycles，它会随着每轮GC自增，也就等于
记录了当前执行到第几轮。runtime.GC（）函数会先读取work.cycles的值，然后把这个值加一作为
n来构造一个gcTriggerCycle类型的gcTrigger，把它作为参数来调用gcStart（）函数。如果在这个过
程中，下一轮GC已经在别处被触发，则work.cycles的值就会等于甚至大于t.n的值，t.test（）函数

就会返回false，gcStart（）函数也就随之返回，不会再重复执行了。

实际发起周期性GC的是forcegchelper协程，它是在runtime的init（）函数中被创建的，入口函数的
代码如下：

它开始运行之后做的第一件事就是获取自身的g指针并赋值给forcegc.g，这样一来sysmon线程就可
以通过forcegc.g来调度当前goroutine了。接下来它初始化了互斥锁forcegc.lock，然后就进入了一个
无限循环。

每轮循环中先获得forcegc.lock锁，然后将forcegc.idle置为 1 ，这样sysmon就能知道forcegchelper协程
当前并没有在运行。设置完idle之后，通过goparkunlock（）函数来挂起自己，同时解锁
forcegc.lock，此后便等待sysmon调度。得到调度执行后，调用gcStart（）函数发起一轮GC，触发
类型为gcTriggerTime。

相应地，sysmon线程中调度forcegchelper的代码如下：

先用当前时间创建一个类型为gcTriggerTime的gcTrigger，然后调用test方法来判断当前时间是否已
经满足GC触发条件。如果达到GC触发条件且forcegchelper处于idle状态，就把forcegc.g添加到runq
中。

3 ． gcTriggerCycle

至于用户可以强制执行GC的runtime.GC（）函数，关键代码如下：

笔者略去了少量不太重要的逻辑，首先从work.cycles获取当前GC的周期数并存于局部变量n中，然
后通过gcWaitOnMark等待第n轮标记结束，然后调用gcStart（）函数发起第n+1轮GC，并等待其标
记结束，最后用一个for循环来完成第n+1轮的清扫工作。

关于GC触发方式的分析就到这里，感兴趣的读者可以深入研究一下gcStart（）等函数的源码。

8.2.5 GC Worker

GC的标记阶段会创建一组后台工作协程，还会启用assist机制让一般的协程在分配内存时辅助完成
一部分标记工作。GC与一般的业务协程是并发运行的，为了避免GC过多地占用CPU，runtime中的
常量gcGoalUtilization将最大使用率限制为30%，常量gcBackgroundUtilization将后台工作协程的最
大CPU使用率限制为25%，两者之差（5%）是留给辅助GC的。

我们先来看一看后台工作协程的这个25%是如何实现的。这组协程是在哪里被创建的呢？是由
gcBgMarkStartWorkers（）函数创建的，该函数的代码如下：

该函数通过一个for循环，创建gomaxprocs个工作协程，也就是保证每个P都能分配到一个。因为
gomaxprocs可能会变化，所以用变量gcBgMarkWorkerCount记录了工作协程的数量，后续如果
gomaxprocs被增大，下次调用该函数时就能把工作协程补齐。gomaxprocs减小，不需要销毁对应的
工作协程，可以留待后续gomaxprocs再次被增大时复用。gcStart（）函数每次都会调用该函数，也
就是每轮GC开始时都会检测后台协程数量，并按需补齐到gomaxprocs个。

感兴趣的读者可以阅读一下gcBgMarkWorker的源码，主要逻辑就是在一个for循环中执行标记逻辑
并检测分布式标记是否已完成。在每轮循环的最开始，它会先通过gopark挂起自己，并且把自己
push到gcBgMarkWorkerPool中，我们感兴趣的是这些后台协程是如何得到调度的。进一步跟踪
gcBgMarkWorkerPool的pop操作，发现有两个地方会调用pop，一个是在gcControllerState类型的
findRunnableGCWorker（）方法中，另一个是在调度循环的findrunnable（）函数中。到这里有必要
介绍一下后台工作协程的几种不同工作模式。

1 ． GC Worker 的工作模式

在runtime中为GC工作协程定义了 3 种工作模式，分别有与之对应的常量，如表8-4所示。

表8-4 GC工作协程的 3 种工作模式及其含义

在以上 3 种模式中，idle模式的worker由findrunnable（）函数负责调度，当findrunnable（）函数找
不到其他可运行的g时，就会从gcBgMarkWorkerPool中pop出一个后台工作协程的g，然后把当前P
的gcMarkWorkerMode设置成gcMarkWorkerIdleMode，并返回工作协程的g。

我们更关心的是dedicated和fractional这两种模式是如何调度的，跟踪findRunnableGCWorker（）方
法，发现整个runtime中只有schedule（）函数会调用它。第 6 章我们分析过schedule（）函数的源
码，它就是调度循环的具体实现，它会先调用findRunnableGCWorker（）方法来尝试执行GC后台
任务，然后才是从runq中取常规g来执行，所以关键点就在于findRunnableGCWorker（）方法了，
代码如下：

其中gcMarkWorkAvailable（）函数会检查P本地的GC工作队列和全局工作队列，如果已经没有任

务需要处理，就直接返回nil。否则就从gcBgMarkWorkerPool中pop出一个工作协程，如果为nil，则
直接返回nil。decIfPositive（）函数基于原子指令CAS实现对一个正整数减一的操作，被用于分配
dedicated模式的worker，优先返回dedicated模式的worker。之后再根据c.fractionalUtilizationGoal来
调度fractional模式的worker。c.dedicatedMarkWorkersNeeded和c.fractionalUtilizationGoal都是在本轮
GC开始时计算出来的，分别表示dedicated、fractional模式的worker会占用多少个P。delta是从本轮
开始标记已经过去的时间，用当前P的gcFractionalMarkTime除以delta得到的是当前P运行fractional
worker所花时间占总时间的百分比，这样可以把fractional worker分摊到所有P上去执行，尽量使每
个P都均衡地分担任务。如果当前P的执行时间已经超过目标值，就返回nil。

最后，我们再来看一下辅助GC，辅助GC虽然不属于GC Worker，但是做的工作也是并发标记工
作，所以也需要了解一下。

2 ．辅助 GC

辅助GC是通过gcAssistAlloc（）函数完成的，整个runtime中只有一个地方会调用该函数，也就是
在mallocgc（）函数中。8.1.6节我们已经知道，g的gcAssistBytes字段记录了当前协程通过辅助GC
积累了多少字节的信用值，就像信用卡的额度一样，如果mallocgc（）函数要分配的内存大小在这
个信用值的范围内，就不用执行辅助GC，否则就要调用gcAssistAlloc（）函数来执行一部分辅助工
作。信用值的存取模型如图8-30所示。

gcAssistAlloc（）函数里有两段代码比较有价值，我们来分析一下。用来计算负债额度和扫描工作
量的代码如下：

图8-30 辅助GC信用值存取模型
assistWorkPerByte实际上是个float64，表示每分配一字节内存空间应该相应地做多少扫描工作，
gcController把它当成uint64进行原子性存取。assistBytesPerWork可以认为是前者的倒数，理解成完
成一字节的扫描工作后可以分配多大的内存空间。这两者表示的都是比率，实际的内存分配和扫描

不可能都是一字节一字节的。它们都是在每轮GC开始时被计算好，并且会随着堆扫描的进度一起
更新。在mallocgc（）函数中，因为gp.gcAssistBytes＜ 0 ，所以才调用了gcAssistAlloc，由此负债额
度就是gp.gcAssistBytes的绝对值。预期需要扫描的大小等于debtBytes乘以assistWorkPerByte，如果
得到的结果小于gcOverAssistWork，就取gcOverAssistWork的值，该值目前被定义为64KB。也就是
至少扫描64KB空间，这样可以避免多次执行而实际的产出过少，就像线程切换频繁造成整体的吞
吐量低下。如果把scanWork对齐到gcOverAssistWork，就需要乘以assistBytesPerWork重新计算
debtBytes。得到的debtBytes会比本次分配的实际需要大一些，但是没有关系，后面它会被累加到
gp.gcAssistBytes中，多出来的部分可供下次分配使用。

还有一段代码用来从gcController窃取扫描信用额度，后台工作协程执行扫描任务积累的信用值会
被累加到gcController的bgScanCredit字段，如果该值的大小足够抵消本次的scanWork，则当前协程
就不用实际去执行扫描任务了。信用窃取的主要代码如下：

根据bgScanCredit与scanWork的大小比较，决定是窃取全部还是窃取部分，并且根据实际窃取的大
小更新gp.gcAssistBytes，然后从bgScanCredit和scanWork中分别减去窃取的大小。最后，如果
scanWork等于 0 ，就不用执行后续的扫描工作了。实现辅助GC主要是为了避免程序过于频繁地分配
内存，造成后台工作协程忙不过来，如果程序的内存分配动作不是很频繁，实际上可能根本不会真
正去执行辅助扫描。

本节关于GC Worker的分析就到这里，感兴趣的读者可阅读源码了解更多细节。

8.2.6 gctrace

讲了较多干巴巴的理论和代码，本节就来点相关实践，验证一下前面的分析探索。Go的runtime对
追踪和调试支持得比较好，例如最常用的pprof，在查找内存泄漏及性能瓶颈时非常方便。垃圾回
收方面可以通过GODEBUG环境变量开启gctrace，程序运行时就会输出每轮GC的开始时间、耗
时，以及标记终止时的堆大小和标记大小等信息。

接下来我们就用几段实际的代码来演示一下，首先来个简单一点的，代码如下：

用go build命令构建上述代码，然后通过GODEBUG环境变量指定gctrace＝ 1 来运行可执行文件，得
到输出如下：

输出的这两行日志包含较多信息，我们一项一项来梳理。拿第一条日志来分析，开头处gc 1中的数
字 1 是序号，表示这是当前进程第一次GC。接下来的@0.022s表示GC开始的时刻，也就是程序开始
执行的22ms后。后面的0%表示GC占用CPU的比例，0+0.92+0分别是清扫终止、并发标记和标记终
止这 3 个阶段耗费的时间，以毫秒为单位。后面的0+0/0.92/0+0进一步细化地给出了清扫终止、辅助
GC、dedicated加fractional标记、idle标记，以及标记终止这 5 项所耗费的CPU时间。4->4->0 MB对
应标记开始时堆的大小、标记结束时堆的大小和标记结束时实际标记的空间大小。5 MB goal表示
预期标记结束时的堆大小。8 P是本轮GC时runtime中P的数量。

初次触发GC的堆大小的临界值是4MB，这与之前的代码分析一致。因为首次标记后存活的堆大小
是0MB，所以临界值保持在4MB没有升高。我们的代码分配了 100 万个int64，总计消耗8MB的堆空
间，所以总共发生了两次GC。

我们稍微改动一下测试代码，把循环次数由 100 万次改成 1000 万次，这样一来GC次数就变多了，在
笔者的计算机上发生了 19 次。虽然次数变多了，但是标记前后的堆大小和实际标记的大小一直是4-

4->0MB，goal也一直保持在5MB。我们可以试着通过GOGC环境变量把gcpercent改得大一些。
gcpercent的默认值是 100 ，意味着堆大小比上次标记大小增长了一倍时触发下次GC。我们把它改成
300 ，也就是增长三倍时触发下次GC。得到的输出如下：

原来的4MB变成了12MB，也就是把首次触发的临界值调高了三倍。每次标记之后实际标记的大小
都是0MB，因为我们的代码把每次循环分配的int64的地址都赋给了同一个包级别指针，这样后面
的指针就会覆盖前面的指针，最后一次之前的指针都会变成不可达。我们再稍微修改一下代码逻
辑，用一个包级别的指针数组使分配的int64全都可达，代码如下：

包级别变量pa是个大小为 1000 万的int64指针数组，我们循环分配 1000 万个int64，通过pa数组保证它
们都可达。运行得到的输出如下：

这次共发生了 5 次GC，可以看到每次标记开始时的堆大小相对于上次实际标记的大小基本上成二倍
关系，并且GC占用CPU的百分比显著增加。不过由于所有分配均可达，造成每次标记终止时的堆
大小和实际标记大小基本相等。我们再修改一下代码，让一半分配可达，另一半不可达，具体的代
码如下：
我们在每轮循环中连续分配两个int64，地址都赋给pa[i]，这样后面的指针就会覆盖掉前面的指针，
从而实现我们想要的一半可达的效果。这次运行得到的输出如下：

堆的大小确实增加了，但是实际标记的大小还是和堆大小基本一致，这是怎么回事呢？对了，我们
忘了tiny allocator，小于 16 字节且noscan的内存块会用tiny分配器进行组合分配。这里相邻的两次
int64分配肯定被tiny allocator组合分配了，所以只要其中一个还是可达的，整个内存块就会被标
记。我们可以再修改一下代码来绕过tiny分配器，可选分配scan型内存，或分配不小于 16 字节的内
存块，我们选择前者，改成分配*int64，代码如下：

这次不是noscan分配了，所以不能使用tiny allocator。实际运行后的输出如下：

这次标记终止时的堆大小和实际标记大小终于不相等了，也就是有可回收的空间了。关于gctrace的
探索就到这里，大家可以设计更有意思的测试代码进行实验。

使用Go提供的trace包结合trace工具，还能以图形化的形式更直观地展示各种追踪数据，其中就包
含与堆和GC相关的信息。我们再来简单地看一下，准备的示例代码如下：

代码会把trace数据输出到标准输出，我们需要收集这些数据以备进一步分析，所以运行可执行文件
时要把标准输出重定向到一个文件，命令如下：

然后使用trace工具来分析out.dat文件，命令如下：

该命令会自动打开一个浏览器窗口，在打开的页面中单击View trace链接，然后就能看到如图8-31
所示的图形界面了。

可以看到在程序运行的整个生命周期中堆的大小变化和GC运行的时段，以及各个P在不同时段分别
在执行什么。笔者的计算机是 8 核CPU，所以可以看到 8 个P中有两个在执行dedicated工作协程，还
可以看到有的P在某个时段执行了辅助GC等。

图8-31 trace命令图形界面

8.3 本章小结
本章主要探索了Go的堆内存管理，写作时主要参考了Go 1.16版及之前几个版本的runtime。前半部
分以内存分配为主线，首先了解了借鉴自tcmalloc的基于sizeclasses的空闲链表，然后重点分析了最
关键的基于arena和span的内存空间管理，以及用于管理和本地缓存mspan的mcentral和mcache结
构，最后梳理了mallocgc（）函数的主要流程和 3 种内存分配策略。后半部分探索了垃圾回收，在
了解了GC的大致流程之后，重点分析了GC root、三色抽象、写屏障等几个关键概念。最后介绍了
gctrace的用法，为大家进一步探索GC提供了一个思路，更多精彩发现期待大家动手探索。
